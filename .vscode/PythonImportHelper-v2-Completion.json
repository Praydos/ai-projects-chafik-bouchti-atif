[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "render_template",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "load_model",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def load_model():\n    \"\"\"Loads the model and tokenizer globally.\"\"\"\n    global tokenizer, infer, NUM_CLASSES\n    print(\"ðŸ¤– Loading tokenizer...\")\n    try:\n        # Load tokenizer\n        tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n        print(\"âœ… Tokenizer loaded.\")\n        print(\"ðŸ§  Loading TensorFlow SavedModel...\")\n        # Load the SavedModel",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "home",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def home():\n    \"\"\"Renders the main HTML page.\"\"\"\n    return render_template('index.html')\n@app.route('/predict', methods=['POST'])\ndef handle_predict():\n    \"\"\"Handles the POST request for prediction and returns JSON.\"\"\"\n    if request.is_json:\n        data = request.get_json()\n        text = data.get('text', '')\n    else:",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "handle_predict",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def handle_predict():\n    \"\"\"Handles the POST request for prediction and returns JSON.\"\"\"\n    if request.is_json:\n        data = request.get_json()\n        text = data.get('text', '')\n    else:\n        text = request.form.get('text', '')\n    if not text:\n        return jsonify({'error': 'No text provided for classification.'}), 400\n    try:",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "health_check",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def health_check():\n    \"\"\"Health check endpoint for monitoring.\"\"\"\n    return jsonify({\n        'status': 'healthy',\n        'model_loaded': infer is not None,\n        'tokenizer_loaded': tokenizer is not None,\n        'timestamp': datetime.now().isoformat()\n    })\n@app.route('/model-info', methods=['GET'])\ndef model_info():",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "model_info",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def model_info():\n    \"\"\"Returns information about the loaded model.\"\"\"\n    return jsonify({\n        'model_name': 'BERT News Classifier',\n        'classes': CLASS_NAMES,\n        'max_length': MAX_LENGTH,\n        'num_classes': NUM_CLASSES,\n        'model_path': MODEL_PATH\n    })\nif __name__ == '__main__':",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "SAVE_DIR",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "SAVE_DIR = \"saved_models\" \nMODEL_PATH = os.path.join(SAVE_DIR, \"bert_sentiment_20251206_162615\")\nTOKENIZER_PATH = os.path.join(SAVE_DIR, \"tokenizer\")\n# The class names for the AG_News dataset\nCLASS_NAMES = ['World', 'Sports', 'Business', 'Sci/Tech']\nMAX_LENGTH = 128\n# Global variables for model and tokenizer\ntokenizer = None\ninfer = None\nNUM_CLASSES = 0",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "MODEL_PATH",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "MODEL_PATH = os.path.join(SAVE_DIR, \"bert_sentiment_20251206_162615\")\nTOKENIZER_PATH = os.path.join(SAVE_DIR, \"tokenizer\")\n# The class names for the AG_News dataset\nCLASS_NAMES = ['World', 'Sports', 'Business', 'Sci/Tech']\nMAX_LENGTH = 128\n# Global variables for model and tokenizer\ntokenizer = None\ninfer = None\nNUM_CLASSES = 0\ndef load_model():",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "TOKENIZER_PATH",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "TOKENIZER_PATH = os.path.join(SAVE_DIR, \"tokenizer\")\n# The class names for the AG_News dataset\nCLASS_NAMES = ['World', 'Sports', 'Business', 'Sci/Tech']\nMAX_LENGTH = 128\n# Global variables for model and tokenizer\ntokenizer = None\ninfer = None\nNUM_CLASSES = 0\ndef load_model():\n    \"\"\"Loads the model and tokenizer globally.\"\"\"",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "CLASS_NAMES",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "CLASS_NAMES = ['World', 'Sports', 'Business', 'Sci/Tech']\nMAX_LENGTH = 128\n# Global variables for model and tokenizer\ntokenizer = None\ninfer = None\nNUM_CLASSES = 0\ndef load_model():\n    \"\"\"Loads the model and tokenizer globally.\"\"\"\n    global tokenizer, infer, NUM_CLASSES\n    print(\"ðŸ¤– Loading tokenizer...\")",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "MAX_LENGTH",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "MAX_LENGTH = 128\n# Global variables for model and tokenizer\ntokenizer = None\ninfer = None\nNUM_CLASSES = 0\ndef load_model():\n    \"\"\"Loads the model and tokenizer globally.\"\"\"\n    global tokenizer, infer, NUM_CLASSES\n    print(\"ðŸ¤– Loading tokenizer...\")\n    try:",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "tokenizer",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "tokenizer = None\ninfer = None\nNUM_CLASSES = 0\ndef load_model():\n    \"\"\"Loads the model and tokenizer globally.\"\"\"\n    global tokenizer, infer, NUM_CLASSES\n    print(\"ðŸ¤– Loading tokenizer...\")\n    try:\n        # Load tokenizer\n        tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "infer",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "infer = None\nNUM_CLASSES = 0\ndef load_model():\n    \"\"\"Loads the model and tokenizer globally.\"\"\"\n    global tokenizer, infer, NUM_CLASSES\n    print(\"ðŸ¤– Loading tokenizer...\")\n    try:\n        # Load tokenizer\n        tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n        print(\"âœ… Tokenizer loaded.\")",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "NUM_CLASSES",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "NUM_CLASSES = 0\ndef load_model():\n    \"\"\"Loads the model and tokenizer globally.\"\"\"\n    global tokenizer, infer, NUM_CLASSES\n    print(\"ðŸ¤– Loading tokenizer...\")\n    try:\n        # Load tokenizer\n        tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n        print(\"âœ… Tokenizer loaded.\")\n        print(\"ðŸ§  Loading TensorFlow SavedModel...\")",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "app = Flask(__name__)\n# Load the model when the Flask application starts\nwith app.app_context():\n    load_model()\n# --- Routes ---\n@app.route('/')\ndef home():\n    \"\"\"Renders the main HTML page.\"\"\"\n    return render_template('index.html')\n@app.route('/predict', methods=['POST'])",
        "detail": "app",
        "documentation": {}
    }
]